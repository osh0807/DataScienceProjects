{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Regression üèò"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Soohoon Oh\n",
    "\n",
    "Contact: soohoonoh@wustl.edu\n",
    "\n",
    "Sources : from Washu CSE217a course materials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using `sklearn` for $k$-Nearest Neighbors\n",
    "\n",
    "In Lab 8, we got familiar with $k$-nearest neighbors ($k$-NN) by implementing the algorithm. If you are still not comfortable with how the algorithm works, then we suggest that you review your work from the lab. In this home work, we will proceed under the assumption that you are familiar with $k$-NN.\n",
    "\n",
    "In this section, we will explore how to use the [$k$-NN _regression_ model supplied by `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor). You can find the [$k$-NN _classification_ model here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Data\n",
    "\n",
    "We'll need to start by getting some data ‚Äî what is data science without data? For this assignment, we will be revisiting another old friend: the Boston Housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X_all, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're here, let's review what this dataset is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.1\n",
    "\n",
    "**Write-up!** How many examples are in the dataset? How many features does it have? What are the features? What is the target variable that we would like to estimate/predict? What kind of machine learning problem is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 506 examples and 14 features. The features are CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT, MEDV. \n",
    "The target we want to estimate is the price of houses in Boston. This is the regression problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Based on our discussions in `Lab4` and `hw4`, we will include all data points and all features but _1000(Bk - 0.63)^2_ where _Bk_ is the proportion of blacks by town encoded as `'B'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'B' feature\n",
    "features_to_use = boston.feature_names!='B'\n",
    "X = X_all[:, features_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data\n",
    "\n",
    "In the lab, we also looked at data scaling and transformations. Here we'll demonstrate how to use `sklearn` to help us with this.\n",
    "\n",
    "**Approach 1:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# new train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)\n",
    "\n",
    "# compute the mean and standard deviation on a training set \n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# apply the transforamtion to both the trainnig and the test set\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2:** \n",
    "An alternative and much quicker way of scaling the the data is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.2\n",
    "\n",
    "**Write-up** What types of scaling does `StandardScaler()` and `scale` perform? Which of the two procedures is a more appropriate preprocessing step for supervised machine learning and _why_? \n",
    "> **Hint:** Use the [`?` operator](https://ipython.readthedocs.io/en/stable/interactive/python-ipython-diff.html#accessing-help) to get more information about the two scaling methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods implement standardization. But we should use Standardscaler() because it divided data into X_test and X_train while scale do scaling with the entire data. If the scale is implemented with the entire data, the mean value changes from the mean of the train data which can lead to incorrect prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Looking Into the Model\n",
    "\n",
    "Now that we have some data to play with, let's try building a $k$-NN regression model. The model provided by `sklearn` shares a similar interface with the other models that we have looked at previously (especially $k$-means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3\n",
    "\n",
    "Use the [`?` operator](https://ipython.readthedocs.io/en/stable/interactive/python-ipython-diff.html#accessing-help) provided by IPython to explore `model` and it's interface.\n",
    "\n",
    "**Do this!** In the cell below, complete the following:\n",
    "1. create and fit a new `KNeighborsRegressor` model with 5 neighbors.\n",
    "2. make some predictions using the model on your testing data.\n",
    "3. evaluate the performance of the model by computing $R^2$ and storing it in `r_squared`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051364300656733"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "new_model = new_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = new_model.predict(X_test)\n",
    "\n",
    "r_squared = r2 = 1 - ((np.square(y_test - y_hat).mean()) / np.var(y_test))\n",
    "\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1c results: All test cases passed!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.4\n",
    "\n",
    "**Write-up!** What was the $R^2$ value for your k-NN model using five neighbors? What does $R^2$ tell you about a model? What does this particular score tell you about your k-NN model?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "**SOLUTION:**\n",
    "R-squared value is in a range from 0 to 1 and a bigger R-squared value indicates better fit. R-squared value of my model is 0.7051364300656733. We can tell it is decent because the score is pretty big among the values in a range from 0 to 1.\n",
    "The particular score of this model indicates that approximately 70% of the observed variation can be explained by the model's input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "With that, let's move on to some more interesting things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing $k$ with Cross Validation\n",
    "\n",
    "In order to test whether the `k-NN` algorithm (or any other machine learning algorithm) performs how we want it to and accurately makes predictions, we must compare the known label of all datapoints to the predicted label of those same datapoints. So far we have seen this in the forms of model evaluation and validation in model selection. \n",
    "\n",
    "In model evaluation we partitioned our original dataset into two parts: a training set and a testing set. As we have seen earlier in the course, the testing set is a smaller percentage of the total dataset than the training set.\n",
    "\n",
    "Later on, in model selection, we explored why it was important to have yet another set of data partitioned out for usage as a validation set, which we could use to experiment with a model's hyperparameters (value that is used to control the learning process). The validation set allowed us to \"evaluate\" our model's performance with various settings of its parameters while maintaining a completely untouched dataset for out final evaluation.\n",
    "\n",
    "We can extend this idea once again to improve our estimates of model performance using **cross validation**.\n",
    "\n",
    "> **CAUTION:** It is a total coincidence that for cross-valiation the number of partitions, also called folds, are typically numbered with the variable _k_. \n",
    "\n",
    "> **This** k **as in \"k-fold cross-validataion\" has nothing to do with the** k **in k-NN!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `kFolds` method\n",
    "\n",
    "One version of cross validation partitions the dataset into `k` partitions, or folds. We use `k-1` folds to train the model and one fold (fold we left out) to test the model. We iterate this process `k` times, leaving out a different fold each time, so that we have an accuracy score for each one of the `k` different partitions. We can then take the average of all of these accuracies to calculate a more wholistic accuracy representation of the algorithm. In the example below, `k = 5`; there are 5 partitions. Each partition is used once as a test partition while the other 4 are used for training purposes. The idea for $k$-fold cross validation is based on the realization that we can get a better picture of our model's performance by feeding it different combinations of our data.\n",
    "\n",
    "![](utility/pics/kFold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [`KFold`üîó](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function from `sklearn`to partition our dataset into `n_splits` partitions. While the `KFold` function does not split the dataset itself, it provides the **indices** on which to split the dataset.\n",
    "\n",
    "Below, we split an random array of length 10 into 5 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [70 60 73 78 99 72 83 15 60 55]\n",
      "For iteration 0: Train indices: [1 2 3 4 5 7 8 9]. Test indices: [0 6]\n",
      "For iteration 1: Train indices: [0 1 2 3 6 7 8 9]. Test indices: [4 5]\n",
      "For iteration 2: Train indices: [0 2 3 4 5 6 7 8]. Test indices: [1 9]\n",
      "For iteration 3: Train indices: [0 1 2 4 5 6 7 9]. Test indices: [3 8]\n",
      "For iteration 4: Train indices: [0 1 3 4 5 6 8 9]. Test indices: [2 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dummy = np.random.randint(10, 100, size = 10) # example data\n",
    "print(f'data: {dummy}')\n",
    "\n",
    "# initialize KFolds\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# iterating over k different splits of dummy\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(dummy)):\n",
    "    print(f'For iteration {fold}: Train indices: {train_idx}. Test indices: {test_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each testing datapoint appears once, ensuring that all datapoints have had a chance to be be tested against the model trained with the rest of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1\n",
    "\n",
    "Now, let's use the `KFold` operation on the full Boston Housing dataset.\n",
    "\n",
    "**Do this!** Complete the `knn_kfolds` function so that it performs `n_folds`-fold cross validation on the dataset `X` and applies $k$-NN regression with k=`n_neighbors` nearest neighbors. The function should return the average $R^2$ value of the model across the folds as `avg_score`.\n",
    "\n",
    "* Make sure to **scale** your training and test sets appropriately (√† la the [Scaling Data](#Scaling-Data) section).\n",
    "* Ensure that you make and **fit a new model** for each fold.\n",
    "* Also, please make sure that you set `random_state` appropriately in your initialization of `KFold`.\n",
    "\n",
    ">**Hint**: Refer to the previous example of how to use `KFold` and your work in [Problem 1.2](#Problem-1.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knn_kfolds(X, y, n_folds, n_neighbors, random_state=None):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state = random_state)\n",
    "    r2scores = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train) \n",
    "        X_test = scaler.transform(X_test) \n",
    "        \n",
    "        model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        model.fit(X_train, y_train)\n",
    "        r_squared = model.score(X_test, y_test)\n",
    "        \n",
    "        r2scores.append(r_squared)\n",
    "        \n",
    "    avg_score = np.mean(r2scores)\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2a results: All test cases passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652077509624957"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_kfolds(X, y, 5, 3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing $k$\n",
    "\n",
    "We can use cross validation as a substitute for the model selection algorithm that we've used in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 2.2\n",
    "\n",
    "In this problem, we will use cross validation and our `knn_kfolds` function to help us pick the right $k$ to use for our Boston Housing predictions.\n",
    "\n",
    "**Do this!** In the following cell, use `knn_kfolds()` to preform 10-fold cross validation on `X` and `y` to evaluate the performance of $k$-NN on the Boston Housing dataset and provide a plot of the cross validation average $R^2$ values for neares neighbor values `k` from 1 to 20 (inclusive). Use a `random_state` of 12 for your analysis. Ensure that your plot has all of the appropriate components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = range(1, 21)\n",
    "avg_arr = []\n",
    "\n",
    "for j in k:\n",
    "    avg_r2score = knn_kfolds(X, y, 10, j, random_state=12)\n",
    "    avg_arr.append(avg_r2score)\n",
    "\n",
    "plt.title('average r-squared values')\n",
    "plt.xlabel(\"number of nearest neighbors\")\n",
    "plt.ylabel('average r-squared values')\n",
    "plt.plot(k, avg_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 2.3\n",
    "\n",
    "**Write-up!** Based on your plot from [Problem 2.2](#Problem-2.2), which $k$ value would you pick for your final model? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would pick 2 for k because it showed the highest average R-squared score. It means the model with 2 neighbors would show the best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3. Model Comparison with Cross Validation\n",
    "\n",
    "As mentioned before, we can use cross validation to get a more thorough evaluation of model performance. Now, we will use CV for model comparison by substituting it in for the model selection process that we have used in above. Note that the approach below is actually not quite legal, since we already used all our data in kNN to select k in **Problem 2.2** and now we are using the _same_ data again to preform model comparison. \n",
    "\n",
    "In this section, we will compare our $k$-NN regression model with a linear regression model that we used back in `Lab4` when we last looked at the Boston Housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1\n",
    "\n",
    "**Do this!** In the following cell, report the cross validation score (average $R^2$) of a $k$-NN model with the $k$ you selected in [Problem 2.3](#Problem-2.3) on `X_scaled`. Use a `random_state` of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799568165440979\n"
     ]
    }
   ],
   "source": [
    "cross_val_score = knn_kfolds(X_scaled, y, 10, 2, random_state=5)\n",
    "print(cross_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.2\n",
    "\n",
    "Now let's do 10-fold cross validation on a linear regression model on `X` without scaling.\n",
    "\n",
    "**Write-up** Why should shouldn't we use scaling here? What will happen if we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the linear regression problem, we get the same model from the same data regardless of wheter we scale the data or not. thus we don't need scaling and moreover, if we scale the data, all the units of data becomes 0 to 1 so the interpretability is also reduced. \n",
    "Therefore, we should not scale the data and directly use the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Do this!** Perform 10-fold cross validation for linear regression on `X` and report the average $R^2$ value across all of the folds.\n",
    "\n",
    "* Ensure that you make and **fit a new model** for each fold.\n",
    "* Use the same random state as we used to evaluate k-NN, so that the cross-validation splits stay the **same**. \n",
    "\n",
    "> **Hint:** Refer to your work in [Problem 2.1](#Problem-2.1) and [Problem 3.1](#Problem-3.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127233828193871"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state = 5)\n",
    "r2_scores = []\n",
    "    \n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    X__train, X__test, y__train, y__test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X__train, y__train)\n",
    "    r__squared = model.score(X__test, y__test)\n",
    "    \n",
    "    r2_scores.append(r__squared)\n",
    "        \n",
    "avg__score = np.mean(r2_scores)\n",
    "\n",
    "avg__score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.3\n",
    "\n",
    "**Write-up!** What were the $R^2$ values for each of the models? Which model would you prefer? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared value of k-NN model is 0.799568165440979 and that of linear regression model is 0.7127233828193871. I would choose k-NN model as it has larger R-squared value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.4\n",
    "\n",
    "**Write-up!** What are your next steps as a data scientist now that you have decided which model to use? Describe two things (related to the DS workflow of this project). Did you notice any thing in our workflow above that was"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I decide the model, I will evaluate the model, by comparing with the ground truth. Then I would communicate the results from the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Write-up!** Did you notice any thing in our workflow above that was not quite right? If so share your critical review with your boss (well for now, with us). Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One concern I found was that we used the transformed dataset, X_scaled, which is made by preprocessing.scale() function with the entire data. We should rather scale the data based on only the part of the dataset, which we defined to be train data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1c results: All test cases passed!\n",
       "\n",
       "q2a results: All test cases passed!\n",
       "\n",
       "q3a results: All test cases passed!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <p>Your submission has been exported. Click <a href=\"hw8_2021_11_23T01_59_04_203024.zip\" download=\"hw8_2021_11_23T01_59_04_203024.zip\" target=\"_blank\">here</a>\n",
       "            to download the zip file.</p>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "otter": {
   "tests": {
    "q1c": {
     "name": "q1c",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(r_squared, 0.70514, rtol=1e-4) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isscalar(knn_kfolds(X, y, 5, 3, random_state=10)) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> avg_score = knn_kfolds(X, y, 5, 3, random_state=10)\n>>> 0 <= avg_score and avg_score <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
